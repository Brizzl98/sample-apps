schema wiki {

  document wiki {
  
    field title type string {
      indexing: summary | index
      index: enable-bm25
    }

    field title_token_ids type tensor<float>(d0[128]) {
        indexing: summary | attribute
    }

    field text type string {
      indexing: summary | index
      index: enable-bm25
    }

    field text_token_ids type tensor<float>(d0[128]) {
      indexing: summary |attribute
    }

    field id type long {
      indexing: summary |attribute
    }

    field text_embedding type tensor<float>(x[769]){
      indexing: attribute|index
      attribute {
        distance-metric:euclidean
      }
      index {
        hnsw {
          max-links-per-node: 32 
          neighbors-to-explore-at-insert: 500
        }
      }
    }
  }
  
  fieldset default {
    fields: title, text 
  }

  rank-profile sparse {
    first-phase {
      expression: bm25(text) + bm25(title) 
    }
  }

  rank-profile dense {
    first-phase {
      expression: closeness(field, text_embedding)
    }
  }

  rank-profile hybrid inherits sparse {
    first-phase {
      expression: 1000*closeness(field, text_embedding) + bm25(text) + bm25(title)
    }
  }
  rank-profile openqa {
    constants {
      TOKEN_NONE: 0
      TOKEN_CLS:  101
      TOKEN_SEP:  102
    }

    # Find length of input
    function input_length() {
      expression: sum(map(query(query_token_ids), f(a)(a > 0)))
    }

    # Find length of the title
    function title_length() {
      expression: sum(map(attribute(title_token_ids), f(a)(a > 0)))
    }

    # Find length of the text
    function text_length() {
      expression: sum(map(attribute(text_token_ids), f(a)(a > 0)))
    }
    # Create input sequence: CLS + query + SEP + title + SEP + text + 0's
    function input_ids() {
      expression {
        tensor<float>(d0[1],d1[128])(
           if (d1 == 0,
             TOKEN_CLS,
           if (d1 < input_length + 1,
             query(query_token_ids){d0:(d1-1)},
           if (d1 == input_length + 1,
             TOKEN_SEP,
           if (d1 < input_length + title_length + 2,
             attribute(title_token_ids){d0:(d1-input_length-2)},
           if (d1 == input_length + title_length + 2,
             TOKEN_SEP,  # ASSUMPTION: input + title length < 126!
           if (d1 < text_length + title_length + input_length + 3,
             attribute(text_token_ids){d0:(d1-input_length-title_length-3)},
              TOKEN_NONE
           )))))))
       }
    }
    # The attention mask has 1's for every token that is set
    function attention_mask() {
      expression: map(input_ids, f(a)(a > 0))
    }
    # Use "output_2" (relevance_logits) as ranking score

    first-phase {
      expression: bm25(title) + bm25(text)
    }

    second-phase {
      rerank-count:10
      expression: sum(onnxModel("files/reader.onnx", "output_2"))
    }
    summary-features {
      onnxModel(files_reader_onnx).output_0
      onnxModel(files_reader_onnx).output_1
    }
  }
}
